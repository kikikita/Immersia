---
title: "LLMGameHub: How We Won the Gradio Agents & MCP Hackathon 2025"
thumbnail: /blog/assets/llmgamehub-hackathon/thumbnail.png
authors:
- user: kikikita
- user: georgiisavin
---

# LLMGameHub: How We Won the Gradio Agents & MCP HackathonÂ 2025
<img width="1300" height="650" alt="thumbnail" src="https://github.com/user-attachments/assets/b209dca3-9bd5-4ab1-9f17-1452dff10223" />

*Create. Play. Imagine.*

In June 2025, my partner and I participated in the international [Gradio Agents & MCP Hackathon](https://huggingface.co/Agents-MCP-Hackathon) â€” a week of experimentation with multi-agent systems and MCP. In the Agentic Demo Showcase track, participants had one goal: to demonstrate the real capabilities of multi-agent LLM applications. That's how LLMGameHub was bornâ€”a platform where anyone can create an interactive game in minutes based on their own ideas and texts.

## How the Idea Was Born

In the beginning was the word, and the word was creativity. We pondered deeply how to showcase the full power of a multi-agent system while ensuring the product appealed to as many people as possible. What do people enjoy? Music, movies, gamesâ€¦ Games! Thatâ€™s what people genuinely love, blending the best aspects of all creative forms. Thus, the idea was born: to unite generative models for text, images, and music into a cohesive ecosystem, enabling users to feel like both directors and writers, crafting their own stories. The hackathon was the perfect opportunity to turn this ambitious concept into a fully operational prototype.

## What is LLMGameHub?

LLMGameHub is a playground for generative adventures. You describe a world, choose a hero and a genreâ€”and immediately dive into the game. The story unfolds on-screen: scenes are generated by a large language model, first-person images are dynamically created, and adaptive music accompanies each plot twist. All of this is powered by a Gradio interface and a backend pool of agents.

Each session lasts around five minutes, featuring several choices, interactive forks, and an ending.

## ðŸš€ How Does it Work?
<img width="1536" height="1024" alt="f70fa09a-9ee9-4861-9eb7-ac13cfe7b870" src="https://github.com/user-attachments/assets/db78a779-47d4-41b9-8afa-11865c0a8b69" />

At the core of LLMGameHub is a set of specialized agents, each responsible for a particular aspect of the game:

* **Story Agent** generates plot scenes and player action options. We use LangGraph and LangChain to build a dialogue graph that directs the narrative flow.
* **Image Agent** dynamically creates or modifies images using Google Gemini, analyzing scenes and generating prompts to visualize them from a first-person perspective.
* **Music Agent** produces atmospheric soundtracks via Google Lyria, dynamically altering the composition's mood according to the narrative.
* **State Manager** stores game progress in Redis, ensuring logical story continuity and accounting for previous player actions.

All agents operate asynchronously, with communication managed through Gradio Blocks, allowing users to see text, select actions, receive images, and hear music with minimal latency.

### Example Node in `llm_graph.py`

```python
async def player_step(state: GraphState) -> GraphState:
    # Save player's choice
    await update_state_with_choice(state.user_hash, state.choice_text)
    # Check if the game has reached an ending
    ending = await check_ending(state.user_hash)
    if ending["ending_reached"]:
        state.ending = ending
        return state
    # Generate the next scene and simultaneously launch music and images
    next_scene = await generate_scene(state.user_hash, state.choice_text)
    await asyncio.gather(
        generate_scene_image(state.user_hash, next_scene),
        generate_music_prompt(state.user_hash, next_scene),
    )
    state.scene = next_scene
    return state
```

This fragment illustrates how the graph decides the next events following a player's choice. Music and image generation are initiated concurrently.

## User Interface
<img width="1536" height="1024" alt="interface" src="https://github.com/user-attachments/assets/52597acb-4994-4434-98c3-3390e409f7d4" />

Our goal was to make playing as enjoyable as story creation. The Gradio-based builder lets you specify the setting, main character, and genre of your future story. After clicking "Start Game," the user instantly immerses themselves in the narrative: text, background illustrations, interactive action choices, and dynamic music.

## Secret of Success

The main challenge was integrating multiple generative services while ensuring acceptable response times. We optimized prompts, leveraged asynchronous programming, executed parallel generation requests, and stored intermediate results in Redis. This approach minimized response times and significantly enhanced user experience.

We also prioritized content safety, implementing prompt checks to eliminate any possibility of generating undesirable images or audio.

## Whatâ€™s Next?

We've already published the project on [Hugging Face Spaces](https://huggingface.co/spaces/Agents-MCP-Hackathon/LLMGameHub) and continue its development by adding new genres and improving music generation. A demo of the project is available on [youtube](https://youtu.be/pQfP9lA1QUM).

## Conclusion

Participating in the hackathon was a true adventure for us. We became acquainted with powerful tools, broadened our technical horizons, and discovered that multi-agent applications can be both useful and incredibly engaging. Winning came as a genuine surprise (though we certainly believed in our abilities!) and motivated us to continue developing both the project and ourselves in this exciting field.

We thank the organizers for the opportunity to showcase our talents and invite everyone to support the project on [our website](https://www.immersia.fun/) â€” your feedback will help us make LLMGameHub even better!
